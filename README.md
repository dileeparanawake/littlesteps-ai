# littlesteps-ai

Full-stack AI milestone tracker for parents â€” built with Next.js, Docker, and OpenAI.

A secure, containerized LLM interface for developmental guidance. Each feature is delivered as a vertical slice (MVS) [read MVS blog post](https://dileeparanawake.com/minimum-viable-slice) to showcase real-world planning, devops, and full-stack skills.

[Project Kanban](https://github.com/users/dileeparanawake/projects/4/views/1)

## Screenshot: MVS 1 Complete: Next.js Prompt Interface + Docker Compose Setup

![LittleSteps AI Screenshot](./public/screenshots/littlesteps_screenshot_2025-07-17_MVS1_complete.png)

Simple frontend + backend OpenAI integration, containerized for local development.

## ğŸ¯ Milestone: MVS 1 â€” Prompt Interface (No Auth)

ğŸ”— [View source at MVS1 tag](https://github.com/dileeparanawake/littlesteps-ai/releases/tag/mvs1-complete) â€“ snapshot of the code at milestone completion

**Goal:** A basic prompt/response interface using OpenAI, containerized for local dev.

### âœ… Features

- Next.js frontend with text input + response output
- Backend API route (`/api/prompt`) to call OpenAI securely
- Docker + Docker Compose for local development
- `.env` config with secure key handling

### âŒ Not Included (Out of Scope)

- Auth or user accounts
- Prompt history or streaming
- Conversational context or personalization

## ğŸ³ Local Development with Docker (suggested)

You can run the full-stack app (Next.js frontend + API) using Docker and Docker Compose.

### ğŸ”§ Prerequisites

- [Docker](https://docs.docker.com/get-docker/) and [Docker Compose](https://docs.docker.com/compose/install/) installed
- `.env` file with your `OPENAI_API_KEY` at the project root (see `.env.example`)

### ğŸš€ Run the app in Docker

```bash
docker-compose up --build
```

- The app will be available at [http://localhost:3000](http://localhost:3000)
- Hot reloading is enabled (via bind-mounted volume)

### ğŸ›‘ Stop the app

```bash
docker-compose down
```

### ğŸ“ Notes

- `/app/node_modules` is isolated from the host to prevent dependency conflicts
- Build artifacts like `.next/` will appear locally (just like running `pnpm dev` outside Docker)

### ğŸ“„ Example `.env` file

```env
# .env.example
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_API_MOCK_KEY=sk-0
MOCK_API=false
```

## âš™ï¸ Local Development (without Docker using Next.js)

### Running locally without Docker

First, run the development server:

**Note** you may see â€œignored build scriptsâ€ on first install. Run pnpm approve-builds if needed.

```bash
pnpm dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

## ğŸ”§ Tech Stack

- **Next.js** â€“ Full-stack React framework (frontend + backend API routes)
- **TypeScript** â€“ Type-safe JavaScript development
- **pnpm** â€“ Fast and efficient package manager
- **OpenAI API** â€“ LLM-powered prompt/response generation
- **Docker** â€“ Containerized dev environment
- **Docker Compose** â€“ Local orchestration (frontend + API, with volumes)
- **Tailwind CSS** â€“ Utility-first styling
- **shadcn/ui** â€“ Accessible prebuilt React UI components
- **.env config** â€“ Secure handling of API keys and environment toggles

## ğŸ”ª Planned MVS Slices

Each slice represents a testable, deployable vertical feature. Completed items are ticked as we go.

- [x] **MVS 1: Prompt Interface** â€“ Basic frontend + backend OpenAI prompt-response with Docker Compose.
- [ ] **MVS 2: User Authentication** â€“ Google OAuth login, JWT session, and protected routes.
- [ ] **MVS 3: Prompt History & Persistence** â€“ PostgreSQL + Drizzle ORM to store user prompts & responses.
- [ ] **MVS 3a: Rate Limiting** â€“ Prevent excessive requests to OpenAI and login endpoints.
- [ ] **MVS 4: Hosting & Deployment** â€“ Deploy via Docker to DigitalOcean with secure config and optional CI/CD.
- [ ] **MVS 5: Milestone Guidance** â€“ Use LLM to suggest parenting milestones based on prompt history.

## ğŸ“ License

This project is licensed under the [MIT License](./LICENSE).
